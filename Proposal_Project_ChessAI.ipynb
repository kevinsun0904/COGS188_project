{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Kevin Sun\n",
    "- Zhencheng Lin\n",
    "- Kaustubh Paliwal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "The goal of this project is to develop a chess AI that adjusts its playing strength based on user-specified Elo ratings, providing an experience that matches the skill level of the player. We will use three datasets: the World Chess Championship Matches (1866-2021), a large collection of 6.2 million games from Lichess, and a smaller set of 20,000 games from Lichess. These datasets represent historical professional matches, a diverse set of player Elo ratings, and a benchmark for comparison, respectively. The data includes game results, player ratings, move sequences, and opening strategies. Our approach will involve training the AI on high-level professional games to understand expert-level play, using the large Lichess dataset to expose the model to a wide variety of player skills, and evaluating the AI’s performance against Stockfish. The AI’s performance will be measured by how well it adjusts to different Elo ratings, its ability to predict optimal moves, and how closely its performance aligns with the Stockfish engine across various game conditions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "The development of chess AI has a rich history, beginning with early efforts in the 1950s when Claude Shannon proposed a framework for a chess-playing algorithm <a name=\"shannon\"></a>[<sup>[1]</sup>](#shannonnote). Over the decades, advancements in artificial intelligence, particularly in machine learning and neural networks, have significantly improved the performance of chess engines. A pivotal moment in AI's history within chess was IBM's Deep Blue, which defeated World Champion Garry Kasparov in 1997, marking the first time a machine beat a reigning world champion <a name=\"campbell\"></a>[<sup>[2]</sup>](#campbellnote).\n",
    "\n",
    "The integration of Reinforcement Learning (RL) into chess AI has since revolutionized the field. While traditional chess engines, such as Stockfish, rely on exhaustive search algorithms and handcrafted evaluation functions, RL-based models, such as DeepMind's AlphaZero, have demonstrated a different approach. AlphaZero learns to play chess through self-play without any prior human knowledge, using a combination of neural networks and Monte Carlo Tree Search (MCTS) to evaluate positions and select moves. This method allowed AlphaZero to achieve great performance by iterating and learning from its own games <a name=\"silver\"></a>[<sup>[3]</sup>](#silvernote).\n",
    "\n",
    "Despite these advancements, there is still a gap in creating chess AI that can emulate human-like play across a wide range of skill levels. Most chess engines, including AlphaZero, are designed to play at peak strength, which can be impractical for players at lower Elo ratings. While some programs attempt to limit their strength artificially, this often leads to less natural or inconsistent play <a name=\"chesscom\"></a>[<sup>[4]</sup>](#chesscomnote). \n",
    "\n",
    "The Elo rating system provides a standardized way to measure chess skill, assigning numerical values to players based on their performance against others <a name=\"elo\"></a>[<sup>[5]</sup>](#elonote). However, adapting an AI to mimic the playstyles and decision-making processes of players at varying Elo levels remains a complex challenge. Techniques such as Markov Decision Processes (MDPs) and Temporal Difference Learning, which are central to RL, present a promising approach for developing adaptive AI models capable of adjusting their play based on the desired Elo rating. These methods allow the model to continuously update its policy and strategies to better align with different skill levels, offering an opportunity for AI to simulate more human-like play across the Elo spectrum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "The primary challenge is to develop a chess AI that can adjust its playing strength to match a user-specified Elo rating, providing a more personalized and instructive experience for players of varying skill levels. Existing chess engines, including those based on traditional search algorithms (e.g., Stockfish) and reinforcement learning (e.g., AlphaZero), are typically designed to perform at their peak strength, which makes them less suitable for training or recreational play for players at lower Elo ratings. Current AI solutions lack the ability to dynamically scale their performance to different skill levels in a natural, human-like manner.\n",
    "\n",
    "To solve this, we propose using Reinforcement Learning (RL) techniques, including Neural Networks, Monte Carlo Tree Search (MCTS), Markov Decision Processes (MDPs), and Temporal Difference Learning, to train an AI model on a diverse dataset consisting of 6.5 million games with Elo ratings, move assessments, and other relevant features. The model will learn to replicate the decision-making processes and strategic depth of players across different Elo levels, enabling it to adjust its playing strength based on the user's selected Elo rating.\n",
    "\n",
    "The problem is quantifiable as the AI's performance can be compared against established Elo benchmarks, and its ability to simulate human-like play can be measured using metrics such as Accuracy, Precision, Recall, F1-Score, AUC-ROC, and RMSE. For example, we can compare the AI's performance in terms of win/loss ratios at different Elo levels, and evaluate the quality of its moves using standard move assessment tools. The problem is measurable through game outcomes (e.g., win/loss), the consistency of the AI's performance with a chosen Elo rating, and the smoothness of its transition between different skill levels. The problem is replicable as the training methodology can be applied to similar datasets of chess games, allowing for the development of AIs that adjust their performance across different Elo ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "To train and evaluate our chess AI, we will utilize three datasets, each serving a specific purpose in the development process. All datasets will be cleaned, processed, and converted into uniform CSV files using Pandas to ensure consistency and structure for model training.\n",
    "\n",
    "1. **[World Chess Championship Matches (1866-2021)](https://www.kaggle.com/datasets/zq1200/world-chess-championships-1866-to-2021)**  \n",
    "   This dataset includes three files: *chess_wc_history_games*, *chess_wc_history_moves*, and *eco_codes*. The first file contains 2938 entries with game events, results, dates, players, and Elo ratings. The *chess_wc_history_moves* file details the moves for each game, and *eco_codes* provides opening names and assessments. Each observation consists of a game, including player names, Elo ratings, game outcomes, and move sequences. Critical variables include player names, Elo ratings, and moves. This dataset will be used to train the AI on high-level play, leveraging professional championship matches to build a strong foundation for evaluating chess positions and decision-making.\n",
    "\n",
    "2. **[Chess Games (6.2 Million on LiChess)](https://www.kaggle.com/datasets/arevel/chess-games)**  \n",
    "   This dataset contains 6.25 million games played on Lichess.org during July 2016. It includes details such as event types, player IDs, Elo ratings, results, and move sequences in Movetext format. Important variables include player ratings, game results, and move sequences. The dataset will be processed to filter by Elo ratings and highlight games that include Stockfish evaluations. The large scale and diversity of Elo ratings in this dataset will enable the AI to learn from a wide range of player strengths, ensuring the model's adaptability and performance across different game conditions.\n",
    "\n",
    "3. **[Chess Game Dataset (20,000 Games from Lichess)](https://www.kaggle.com/datasets/arevel/chess-games)**  \n",
    "   This dataset consists of around 20,000 games collected from Lichess using the Lichess API. It contains game IDs, player ratings, number of moves, game status, winners, and move sequences. Critical variables include player ratings, game results, and move sequences in standard chess notation. This dataset will be used to evaluate the performance of our trained model by comparing it against Stockfish, a top-tier chess engine. It will serve as a benchmark for assessing the AI's accuracy and effectiveness in predicting optimal moves across different Elo levels.\n",
    "\n",
    "We will clean, preprocess, and convert all three datasets into uniform CSV files using Pandas, ensuring that they are structured consistently for training purposes. This will facilitate smooth integration and comparison of the datasets, enabling effective training and evaluation of the AI model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "To develop a chess AI that adjusts its playing strength based on Elo ratings, we propose a solution combining machine learning techniques to predict moves, simulate human-like play, and adapt to various skill levels. Our approach integrates position evaluation using a Convolutional Neural Network (CNN), move prediction through a Recurrent Neural Network (RNN), and move exploration via Monte Carlo Tree Search (MCTS).\n",
    "\n",
    "The CNN will evaluate chess positions by predicting the value of a given board state, trained on historical game data. The RNN will use previous moves and current positions to predict the next move, enabling the AI to adapt to different game contexts. MCTS will be employed to simulate possible moves and assess their effectiveness, refining the AI’s decision-making process.\n",
    "\n",
    "Additionally, the AI will adjust its strategy based on the user's Elo rating. For higher-rated players, it will adopt more complex strategies, while for lower-rated players, it will focus on simpler, more human-like moves. This adaptability ensures the AI remains challenging and accessible to players of all skill levels.\n",
    "\n",
    "We will evaluate the performance of this solution by comparing it against Stockfish, a traditional chess engine, using a dataset of 20,000 diverse games. Metrics such as accuracy, precision, recall, F1-score, AUC-ROC, and RMSE will be used to assess the AI's effectiveness in predicting moves and simulating human-like play. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "\n",
    "To evaluate both the benchmark model (Stockfish) and our chess AI, we propose several metrics focusing on move prediction accuracy and adaptability across different Elo ratings. These metrics will be calculated using a third dataset of 20,000 diverse games.\n",
    "\n",
    "- **Accuracy**: Measures the proportion of correct moves predicted by the model.\n",
    "  $$\n",
    "  \\text{Accuracy} = \\frac{\\text{Correct Moves}}{\\text{Total Moves}}\n",
    "  $$\n",
    "  It will be used to assess the overall performance of both models in making correct move predictions.\n",
    "\n",
    "- **Precision**: The proportion of correct valid moves out of all predicted moves.\n",
    "  $$\n",
    "  \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "  $$\n",
    "  This evaluates how accurately the model avoids predicting weak moves.\n",
    "\n",
    "- **Recall**: The proportion of correct valid moves out of all actual valid moves.\n",
    "  $$\n",
    "  \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "  $$\n",
    "  It measures the model's ability to identify all good moves, essential for simulating human-like play.\n",
    "\n",
    "- **F1-Score**: The harmonic mean of precision and recall.\n",
    "  $$\n",
    "  \\text{F1-Score} = \\frac{2 \\cdot \\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "  $$\n",
    "  It balances precision and recall, helping evaluate models that may favor one over the other.\n",
    "\n",
    "- **AUC-ROC**: Measures the model’s ability to distinguish between optimal and suboptimal moves.\n",
    "  $$\n",
    "  \\text{AUC-ROC} = \\text{Area under the ROC curve}\n",
    "  $$\n",
    "  A higher AUC-ROC reflects better performance in identifying optimal moves.\n",
    "\n",
    "- **RMSE (Root Mean Square Error)**: Measures the average magnitude of error in move evaluations.\n",
    "  $$\n",
    "  \\text{RMSE} = \\sqrt{\\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y}_i)^2}\n",
    "  $$\n",
    "  A lower RMSE indicates the model's predictions are closer to actual outcomes.\n",
    "\n",
    "These metrics will be derived and compared by evaluating both models (our solution and Stockfish) on a third-party dataset containing 20,000 diverse games with varying Elo ratings. For each game, both models will predict the next move based on the Elo rating, the position, and the previous and next moves. The metrics (Accuracy, Precision, Recall, F1-Score, AUC-ROC, and RMSE) will be calculated for each model and compared to assess their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the major ethical concerns associated with AI chess bots, such as the one we are developing for this project, is their role in facilitating cheating. The accessibility of powerful engines like Stockfish has led to widespread dishonesty in online chess and, in some cases, even professional tournaments. With these tools readily available, players can gain an unfair advantage, undermining the integrity of competitions and diminishing the skill-based nature of the game. If left unchecked, AI-assisted cheating could erode trust in online platforms and threaten the credibility of chess as a competitive sport.\n",
    "\n",
    "Beyond cheating, the dominance of AI in chess raises concerns about the balance between human skill and technological assistance. Players who rely too heavily on AI for training and move analysis may experience diminished critical thinking and strategic development. While AI can be a valuable tool for improvement, excessive dependence could lead to a generation of players who prioritize engine-generated moves over their own creative play. This shift not only affects individual growth but also alters the broader landscape of competitive chess, where originality and deep positional understanding risk being overshadowed by algorithmic precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will communicate our progress via text messages / discord and keep each other updated. \n",
    "* We will have weekly meetings via zoom / in-person to discuss progress and divide up the work.\n",
    "* Everyone in the team will contribute a similar amount of work no matter technical / non-technical.\n",
    "* When we encounter a conflict, we will discuss the issues and resolve the conflict in a professional manner. \n",
    "* When making major descisions, we will discuss the descision and its outcomes and decide on the descision together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date | Completed Before Meeting  | Discuss at Meeting |  \n",
    "|-------------|-------------------------|---------------------|  \n",
    "| 2/13  | Brainstorm topics/questions  | Discuss topic ideas, decide research question, and divide work for proposal |  \n",
    "| 2/17  | Complete project proposal  | Discuss technical details regarding execution and implementation |  \n",
    "| 2/21  | Gather and preprocess datasets | Review dataset selection, preprocessing steps, and discuss potential issues |  \n",
    "| 2/25  | Initial model setup and baseline evaluation | Evaluate baseline model performance, discuss feature selection and improvements |  \n",
    "| 3/1  | Implement AI model and train on datasets | Analyze initial results, adjust hyperparameters, and refine approach |  \n",
    "| 3/5  | Compare model with Stockfish and evaluate performance | Review evaluation metrics (Accuracy, Precision, Recall, F1-Score, AUC-ROC, RMSE) and analyze results |  \n",
    "| 3/9  | Finalize results and discuss improvements | Summarize findings, refine model if necessary, and outline report structure |  \n",
    "| 3/13  | Complete final report draft | Review and revise report, discuss final presentation details |  \n",
    "| 3/15  | Submit final report and presentation | Ensure all components are complete and ready for submission |  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"shannon\"></a>1.[^](#shannon): Shannon, C. E. (1950). Programming a Computer for Playing Chess. *Philosophical Magazine*.<br>\n",
    "\n",
    "<a name=\"campbell\"></a>2.[^](#campbell): Campbell, M., Hoane, A. J., & Hsu, F. H. (2002). Deep Blue. *Artificial Intelligence*.<br>\n",
    "\n",
    "<a name=\"silver\"></a>3.[^](#silver): Silver, D., et al. (2017). Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm. *arXiv preprint arXiv:1712.01815*.<br>\n",
    "\n",
    "<a name=\"chesscom\"></a>4.[^](#chesscom): Chess.com Forum. (n.d.). Chess program that allows setting Elo rating for computer opponent. Retrieved from [https://www.chess.com/forum/view/general/chess-program-that-allow-to-set-elo-rating-for-computer-opponent?page=2](https://www.chess.com/forum/view/general/chess-program-that-allow-to-set-elo-rating-for-computer-opponent?page=2).<br>\n",
    "\n",
    "<a name=\"elo\"></a>5.[^](#elo): Wikipedia. (n.d.). Elo rating system. Retrieved from [https://en.wikipedia.org/wiki/Elo_rating_system](https://en.wikipedia.org/wiki/Elo_rating_system).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
