{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Require tensorflow version 2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import ast\n",
    "import chess\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "# If you're using the ChessEnv class\n",
    "from stockfish import Stockfish\n",
    "\n",
    "# Configure TensorFlow to use Metal GPU acceleration\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    print(f\"Found {len(physical_devices)} GPU(s):\")\n",
    "    for device in physical_devices:\n",
    "        print(f\"  {device.name}\")\n",
    "    # Configure TensorFlow to use the first GPU\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "        print(f\"Memory growth enabled for {physical_devices[0].name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error configuring GPU: {e}\")\n",
    "else:\n",
    "    print(\"No GPU devices found. Using CPU for computation.\")\n",
    "\n",
    "# Print TensorFlow version and compute device\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Compute device: {tf.config.list_physical_devices()}\")\n",
    "\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print(\"GPU devices available:\")\n",
    "    for gpu in gpu_devices:\n",
    "        print(gpu)\n",
    "else:\n",
    "    print(\"No GPU devices found. Using CPU for computation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep your existing split_dims function here\n",
    "squares_index = {\n",
    "    'a': 0,\n",
    "    'b': 1,\n",
    "    'c': 2,\n",
    "    'd': 3,\n",
    "    'e': 4,\n",
    "    'f': 5,\n",
    "    'g': 6,\n",
    "    'h': 7\n",
    "}\n",
    "\n",
    "def square_to_index(square):\n",
    "    letter = chess.square_name(square)\n",
    "    return 8 - int(letter[1]), squares_index[letter[0]]\n",
    "\n",
    "def split_dims(board):\n",
    "    # this is the 3d matrix\n",
    "    board3d = np.zeros((14, 8, 8), dtype=np.int8)\n",
    "\n",
    "    # here we add the pieces's view on the matrix\n",
    "    for piece in chess.PIECE_TYPES:\n",
    "        for square in board.pieces(piece, chess.WHITE):\n",
    "            idx = np.unravel_index(square, (8, 8))\n",
    "            board3d[piece - 1][7 - idx[0]][idx[1]] = 1\n",
    "        for square in board.pieces(piece, chess.BLACK):\n",
    "            idx = np.unravel_index(square, (8, 8))\n",
    "            board3d[piece + 5][7 - idx[0]][idx[1]] = 1\n",
    "\n",
    "    # add attacks and valid moves too\n",
    "    # so the network knows what is being attacked\n",
    "    aux = board.turn\n",
    "    board.turn = chess.WHITE\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        i, j = square_to_index(move.to_square)\n",
    "        board3d[12][i][j] = 1\n",
    "\n",
    "    board.turn = chess.BLACK\n",
    "\n",
    "    for move in board.legal_moves:\n",
    "        i, j = square_to_index(move.to_square)\n",
    "        board3d[13][i][j] = 1\n",
    "\n",
    "    board.turn = aux\n",
    "\n",
    "    return board3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chess_data(filepath, batch_size=1024):\n",
    "    \"\"\"\n",
    "    Generator to load chess data in batches to avoid memory issues.\n",
    "    \n",
    "    Args:\n",
    "        filepath: Path to the gzipped CSV file\n",
    "        batch_size: Number of samples to load at once\n",
    "        \n",
    "    Yields:\n",
    "        X_batch, y_batch: Features and targets for training\n",
    "    \"\"\"\n",
    "    # Open the gzipped file\n",
    "    with gzip.open(filepath, 'rt') as f:\n",
    "        # Read file in chunks to avoid memory issues\n",
    "        for chunk in pd.read_csv(f, chunksize=batch_size):\n",
    "            X_batch = []\n",
    "            y_batch = []\n",
    "            \n",
    "            for _, row in chunk.iterrows():\n",
    "                # Convert game_state string to numpy array\n",
    "                try:\n",
    "                    # This assumes game_state is stored as a string representation of a numpy array\n",
    "                    # You'll need to adjust this based on how the data is actually stored\n",
    "                    game_state_str = row['game_state']\n",
    "                    \n",
    "                    # Method 1: Using ast.literal_eval (safer but slower)\n",
    "                    # game_state = np.array(ast.literal_eval(game_state_str))\n",
    "                    \n",
    "                    # Method 2: Using numpy's string parsing (adjust as needed)\n",
    "                    # Remove unwanted characters and split into numbers\n",
    "                    # This is a simplified example and may need adjustment based on your data format\n",
    "                    clean_str = game_state_str.replace('[', '').replace(']', '').replace('\\n', ' ')\n",
    "                    values = np.fromstring(clean_str, sep=' ', dtype=np.int8)\n",
    "                    game_state = values.reshape(14, 8, 8)\n",
    "                    \n",
    "                    # Get the evaluation (target)\n",
    "                    eval_score = row['stateEval']\n",
    "                    \n",
    "                    # Normalize evaluation to [-1, 1] range (assuming original range is [-10, 10])\n",
    "                    normalized_eval = eval_score / 10.0\n",
    "                    \n",
    "                    X_batch.append(game_state)\n",
    "                    y_batch.append(normalized_eval)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing row: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if X_batch and y_batch:\n",
    "                yield np.array(X_batch), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_chess_cnn(input_shape=(14, 8, 8)):\n",
    "    \"\"\"\n",
    "    Create a CNN for chess position evaluation.\n",
    "    Optimized for Metal GPU acceleration on macOS.\n",
    "    \n",
    "    Args:\n",
    "        input_shape: Shape of the input tensor (channels, height, width)\n",
    "        \n",
    "    Returns:\n",
    "        A compiled Keras model\n",
    "    \"\"\"\n",
    "    # Enable mixed precision training for better performance on Metal\n",
    "    # This uses both float16 and float32 where appropriate\n",
    "    tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    \n",
    "    model = Sequential([\n",
    "        # First convolutional block\n",
    "        Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu', \n",
    "               input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Fully connected layers\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Output layer (regression for evaluation score)\n",
    "        # Note: We use float32 for the output layer to maintain precision\n",
    "        Dense(1, activation='tanh', dtype='float32')  # Force float32 output\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss='mse',  # Mean squared error for regression\n",
    "        metrics=['mae']  # Mean absolute error to track accuracy\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_chess_cnn(data_path, model_save_path='chess_cnn_model.h5', epochs=20):\n",
    "    \"\"\"\n",
    "    Train the chess CNN on the processed data with Metal optimizations.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to the training data\n",
    "        model_save_path: Where to save the trained model\n",
    "        epochs: Number of training epochs\n",
    "    \"\"\"\n",
    "    # Create the model\n",
    "    model = create_chess_cnn()\n",
    "    model.summary()  # Show model architecture\n",
    "    \n",
    "    # Start overall training timer\n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    # Set up callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "        ModelCheckpoint(filepath=model_save_path, save_best_only=True, monitor='val_loss')\n",
    "    ]\n",
    "    \n",
    "    # Create validation data generator\n",
    "    print(\"Loading validation data...\")\n",
    "    validation_data = None\n",
    "    for X_batch, y_batch in load_chess_data(data_path, batch_size=1024):\n",
    "        validation_data = (X_batch, y_batch)\n",
    "        print(f\"Validation data shape: {X_batch.shape}\")\n",
    "        break  # Just use the first batch as validation data\n",
    "    \n",
    "    # Train on batches\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        batch_count = 0\n",
    "        total_loss = 0\n",
    "        total_mae = 0\n",
    "        \n",
    "        # Process each batch\n",
    "        for X_batch, y_batch in load_chess_data(data_path, batch_size=512):  # Adjusted batch size for Metal\n",
    "            batch_start_time = time.time()\n",
    "            \n",
    "            # Train on this batch\n",
    "            history = model.fit(\n",
    "                X_batch, y_batch,\n",
    "                batch_size=64,  # Optimal batch size for Metal may differ from NVIDIA GPUs\n",
    "                epochs=1,\n",
    "                verbose=0,\n",
    "                validation_data=validation_data\n",
    "            )\n",
    "            \n",
    "            batch_count += 1\n",
    "            total_loss += history.history['loss'][0]\n",
    "            total_mae += history.history['mae'][0]\n",
    "            \n",
    "            batch_time = time.time() - batch_start_time\n",
    "            \n",
    "            # Print progress every 5 batches\n",
    "            if batch_count % 5 == 0:\n",
    "                print(f\"  Batch {batch_count}: Loss = {total_loss/batch_count:.4f}, MAE = {total_mae/batch_count:.4f} (Time: {batch_time:.2f}s)\")\n",
    "                # Force garbage collection to free GPU memory (helpful for Metal)\n",
    "                import gc\n",
    "                gc.collect()\n",
    "        \n",
    "        # Evaluate on validation data at the end of each epoch\n",
    "        eval_start_time = time.time()\n",
    "        val_loss, val_mae = model.evaluate(validation_data[0], validation_data[1], verbose=0)\n",
    "        eval_time = time.time() - eval_start_time\n",
    "        \n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        print(f\"  Epoch {epoch+1} completed in {epoch_time:.2f}s\")\n",
    "        print(f\"  Validation: Loss = {val_loss:.4f}, MAE = {val_mae:.4f} (Eval time: {eval_time:.2f}s)\")\n",
    "    \n",
    "    # Save the final model\n",
    "    model.save(model_save_path)\n",
    "    \n",
    "    # Calculate and print total training time\n",
    "    overall_training_time = time.time() - overall_start_time\n",
    "    hours, remainder = divmod(overall_training_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    print(f\"\\nModel saved to {model_save_path}\")\n",
    "    print(f\"Total training time: {int(hours)}h {int(minutes)}m {seconds:.2f}s\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EloAdaptiveChessAI:\n",
    "    def __init__(self, model_path, min_elo=800, max_elo=2800):\n",
    "        \"\"\"\n",
    "        Initialize the adaptive chess AI with a trained CNN model.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the saved model file\n",
    "            min_elo: Minimum Elo rating the AI can emulate\n",
    "            max_elo: Maximum Elo rating the AI can emulate\n",
    "        \"\"\"\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        self.min_elo = min_elo\n",
    "        self.max_elo = max_elo\n",
    "        self.current_elo = 1500  # Default Elo\n",
    "        \n",
    "    def set_elo(self, elo):\n",
    "        \"\"\"Set the Elo rating for the AI to emulate.\"\"\"\n",
    "        self.current_elo = max(min(elo, self.max_elo), self.min_elo)\n",
    "        \n",
    "    def _calculate_move_quality(self, elo_diff):\n",
    "        \"\"\"\n",
    "        Calculate move quality factor based on Elo difference.\n",
    "        Higher values (closer to 1) mean better moves.\n",
    "        \"\"\"\n",
    "        # This is a simplified model - you'll want to tune this\n",
    "        # We use a sigmoid-like function to map Elo difference to move quality\n",
    "        return 1.0 / (1.0 + np.exp(-elo_diff / 400.0))\n",
    "        \n",
    "    def evaluate_position(self, board):\n",
    "        \"\"\"\n",
    "        Evaluate the board position and adjust based on current Elo.\n",
    "        \n",
    "        Args:\n",
    "            board: Chess board position\n",
    "            \n",
    "        Returns:\n",
    "            Evaluation score adjusted for current Elo\n",
    "        \"\"\"\n",
    "        # Convert board to CNN input format\n",
    "        board_tensor = split_dims(board)\n",
    "        board_tensor = np.expand_dims(board_tensor, axis=0)  # Add batch dimension\n",
    "        \n",
    "        # Get the raw evaluation (normalized between -1 and 1)\n",
    "        raw_eval = self.model.predict(board_tensor, verbose=0)[0][0]\n",
    "        \n",
    "        # Scale back to original range (-10 to 10)\n",
    "        raw_eval = raw_eval * 10.0\n",
    "        \n",
    "        # Calculate move quality based on Elo\n",
    "        # Top GMs/engines are around 3000+ Elo\n",
    "        move_quality = self._calculate_move_quality(self.current_elo - 1500)\n",
    "        \n",
    "        # Mix perfect evaluation with some randomness based on Elo\n",
    "        # Lower Elo means more randomness\n",
    "        noise_factor = 1.0 - move_quality\n",
    "        noise = np.random.normal(0, noise_factor * 2.0)  # Standard deviation scales with Elo\n",
    "        \n",
    "        # Apply noise to the evaluation\n",
    "        adjusted_eval = raw_eval * move_quality + noise\n",
    "        \n",
    "        return adjusted_eval\n",
    "    \n",
    "    def select_move(self, board, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Select a move based on position evaluation and current Elo.\n",
    "        \n",
    "        Args:\n",
    "            board: Chess board position\n",
    "            temperature: Controls randomness of move selection\n",
    "            \n",
    "        Returns:\n",
    "            Selected chess move\n",
    "        \"\"\"\n",
    "        legal_moves = list(board.legal_moves)\n",
    "        if not legal_moves:\n",
    "            return None\n",
    "        \n",
    "        # Evaluate all legal moves\n",
    "        move_scores = []\n",
    "        for move in legal_moves:\n",
    "            # Make the move\n",
    "            board.push(move)\n",
    "            \n",
    "            # Evaluate the new position\n",
    "            score = -self.evaluate_position(board)  # Negate because we're evaluating after our move\n",
    "            \n",
    "            # Undo the move\n",
    "            board.pop()\n",
    "            \n",
    "            move_scores.append((move, score))\n",
    "        \n",
    "        # Adjust temperature based on Elo\n",
    "        # Lower Elo -> higher temperature (more randomness)\n",
    "        elo_factor = (self.max_elo - self.current_elo) / (self.max_elo - self.min_elo)\n",
    "        adjusted_temp = temperature * (1.0 + elo_factor * 2.0)\n",
    "        \n",
    "        # Convert scores to probabilities using softmax with temperature\n",
    "        scores = np.array([score for _, score in move_scores])\n",
    "        probabilities = np.exp(scores / adjusted_temp)\n",
    "        probabilities = probabilities / np.sum(probabilities)\n",
    "        \n",
    "        # Sample a move based on probabilities\n",
    "        move_idx = np.random.choice(len(legal_moves), p=probabilities)\n",
    "        \n",
    "        return move_scores[move_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This assumes you have your ChessEnv class defined elsewhere in the notebook\n",
    "class CNNChessEnv:\n",
    "    \"\"\"\n",
    "    Chess environment that uses a CNN for position evaluation.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path, elo_rating=1500, stockfish_path=None):\n",
    "        \"\"\"\n",
    "        Initialize the CNN-based chess environment.\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the trained CNN model\n",
    "            elo_rating: Initial Elo rating for the AI\n",
    "            stockfish_path: Path to Stockfish executable (optional)\n",
    "        \"\"\"\n",
    "        self.board = chess.Board()\n",
    "        self.chess_ai = EloAdaptiveChessAI(model_path)\n",
    "        self.chess_ai.set_elo(elo_rating)\n",
    "        self.stockfish_path = stockfish_path\n",
    "        self.stockfish = None\n",
    "        \n",
    "        # Initialize Stockfish if path is provided\n",
    "        if stockfish_path:\n",
    "            self.stockfish = Stockfish(path=stockfish_path)\n",
    "            self.stockfish.set_depth(15)\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the board to the starting position.\"\"\"\n",
    "        self.board = chess.Board()\n",
    "        return self.board\n",
    "    \n",
    "    def evaluate_position_cnn(self):\n",
    "        \"\"\"Evaluate position using the CNN.\"\"\"\n",
    "        return self.chess_ai.evaluate_position(self.board)\n",
    "    \n",
    "    def evaluate_position_stockfish(self):\n",
    "        \"\"\"Evaluate position using Stockfish.\"\"\"\n",
    "        if not self.stockfish:\n",
    "            raise ValueError(\"Stockfish not initialized\")\n",
    "        \n",
    "        self.stockfish.set_fen_position(self.board.fen())\n",
    "        evaluation = self.stockfish.get_evaluation()\n",
    "        \n",
    "        # Parse the evaluation\n",
    "        if evaluation[\"type\"] == \"cp\":\n",
    "            # Centipawn evaluation (convert to pawns)\n",
    "            return evaluation[\"value\"] / 100.0\n",
    "        else:\n",
    "            # Mate evaluation\n",
    "            mate_in = evaluation[\"value\"]\n",
    "            if mate_in > 0:\n",
    "                return 9.0 + (1.0 / mate_in)  # Positive for white winning\n",
    "            else:\n",
    "                return -9.0 - (1.0 / mate_in)  # Negative for black winning\n",
    "    \n",
    "    def get_ai_move(self):\n",
    "        \"\"\"Get a move from the AI with the current Elo setting.\"\"\"\n",
    "        return self.chess_ai.select_move(self.board)\n",
    "    \n",
    "    def make_move(self, move):\n",
    "        \"\"\"Make a move on the board.\"\"\"\n",
    "        if move not in self.board.legal_moves:\n",
    "            raise ValueError(f\"Illegal move: {move}\")\n",
    "        \n",
    "        self.board.push(move)\n",
    "        return self.board\n",
    "    \n",
    "    def set_elo(self, elo):\n",
    "        \"\"\"Set the Elo rating for the AI.\"\"\"\n",
    "        self.chess_ai.set_elo(elo)\n",
    "        \n",
    "    def render(self):\n",
    "        \"\"\"Render the board as a string.\"\"\"\n",
    "        return str(self.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_cnn_model(model_path, stockfish_path=None, num_positions=10):\n",
    "    \"\"\"\n",
    "    Test the CNN model against Stockfish for a few positions with timing information.\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the trained CNN model\n",
    "        stockfish_path: Path to Stockfish executable (optional)\n",
    "        num_positions: Number of positions to evaluate\n",
    "    \"\"\"\n",
    "    # Start overall testing timer\n",
    "    overall_start_time = time.time()\n",
    "    \n",
    "    # Initialize environment\n",
    "    print(\"Loading model and initializing environment...\")\n",
    "    env = CNNChessEnv(model_path=model_path, stockfish_path=stockfish_path)\n",
    "    \n",
    "    # Test at different Elo ratings\n",
    "    for elo in [1200, 1600, 2000, 2400]:\n",
    "        print(f\"\\nTesting at Elo {elo}:\")\n",
    "        env.set_elo(elo)\n",
    "        \n",
    "        elo_start_time = time.time()\n",
    "        \n",
    "        # Reset board\n",
    "        env.reset()\n",
    "        \n",
    "        # Make random moves to get to different positions\n",
    "        for i in range(num_positions):\n",
    "            # Make some random moves to get to a position\n",
    "            for _ in range(random.randint(1, 10)):  # 1-10 random moves\n",
    "                legal_moves = list(env.board.legal_moves)\n",
    "                if not legal_moves:\n",
    "                    break\n",
    "                move = random.choice(legal_moves)\n",
    "                env.make_move(move)\n",
    "                \n",
    "                # Stop if game is over\n",
    "                if env.board.is_game_over():\n",
    "                    break\n",
    "            \n",
    "            # Skip if game is over\n",
    "            if env.board.is_game_over():\n",
    "                env.reset()\n",
    "                continue\n",
    "            \n",
    "            position_start_time = time.time()\n",
    "            \n",
    "            # Get CNN evaluation\n",
    "            cnn_start_time = time.time()\n",
    "            cnn_eval = env.evaluate_position_cnn()\n",
    "            cnn_time = time.time() - cnn_start_time\n",
    "            \n",
    "            # Get Stockfish evaluation if available\n",
    "            stockfish_eval = None\n",
    "            stockfish_time = 0\n",
    "            if stockfish_path:\n",
    "                stockfish_start_time = time.time()\n",
    "                stockfish_eval = env.evaluate_position_stockfish()\n",
    "                stockfish_time = time.time() - stockfish_start_time\n",
    "                \n",
    "            # Print comparison\n",
    "            print(f\"\\nPosition {i+1} evaluation (Elo {elo}):\")\n",
    "            print(f\"  CNN: {cnn_eval:.4f} (Time: {cnn_time:.4f}s)\")\n",
    "            if stockfish_eval is not None:\n",
    "                print(f\"  Stockfish: {stockfish_eval:.4f} (Time: {stockfish_time:.4f}s)\")\n",
    "                print(f\"  Difference: {abs(cnn_eval - stockfish_eval):.4f}\")\n",
    "                print(f\"  Speed improvement: {stockfish_time/cnn_time:.2f}x\")\n",
    "            \n",
    "            # Get and print best move\n",
    "            move_start_time = time.time()\n",
    "            best_move = env.get_ai_move()\n",
    "            move_time = time.time() - move_start_time\n",
    "            \n",
    "            print(f\"  AI's chosen move: {best_move} (Time: {move_time:.4f}s)\")\n",
    "            position_time = time.time() - position_start_time\n",
    "            print(f\"  Total position analysis time: {position_time:.4f}s\")\n",
    "            print(f\"  Board:\\n{env.render()}\")\n",
    "            \n",
    "            # Reset for next position\n",
    "            env.reset()\n",
    "        \n",
    "        elo_time = time.time() - elo_start_time\n",
    "        print(f\"\\nCompleted Elo {elo} testing in {elo_time:.2f}s\")\n",
    "    \n",
    "    # Calculate and print total testing time\n",
    "    overall_testing_time = time.time() - overall_start_time\n",
    "    minutes, seconds = divmod(overall_testing_time, 60)\n",
    "    \n",
    "    print(f\"\\nTotal testing time: {int(minutes)}m {seconds:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_performance(seconds=10):\n",
    "    \"\"\"\n",
    "    Monitor system performance metrics including GPU usage.\n",
    "    \n",
    "    Args:\n",
    "        seconds: How long to monitor in seconds\n",
    "    \"\"\"\n",
    "    import psutil\n",
    "    import time\n",
    "    \n",
    "    # Start monitoring\n",
    "    print(\"Starting performance monitoring...\")\n",
    "    start_time = time.time()\n",
    "    end_time = start_time + seconds\n",
    "    \n",
    "    # Initialize counters\n",
    "    count = 0\n",
    "    cpu_percent_total = 0\n",
    "    memory_percent_total = 0\n",
    "    \n",
    "    # Monitor loop\n",
    "    while time.time() < end_time:\n",
    "        # Get CPU usage\n",
    "        cpu_percent = psutil.cpu_percent(interval=1)\n",
    "        \n",
    "        # Get memory usage\n",
    "        memory_info = psutil.virtual_memory()\n",
    "        memory_percent = memory_info.percent\n",
    "        \n",
    "        # Update totals\n",
    "        cpu_percent_total += cpu_percent\n",
    "        memory_percent_total += memory_percent\n",
    "        count += 1\n",
    "        \n",
    "        # Print current values\n",
    "        print(f\"CPU: {cpu_percent}%, Memory: {memory_percent}%\")\n",
    "        \n",
    "        # Brief pause\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_cpu = cpu_percent_total / count\n",
    "    avg_memory = memory_percent_total / count\n",
    "    \n",
    "    print(f\"\\nAverage over {seconds} seconds:\")\n",
    "    print(f\"CPU Usage: {avg_cpu:.1f}%\")\n",
    "    print(f\"Memory Usage: {avg_memory:.1f}%\")\n",
    "    \n",
    "    # Note: Metal GPU monitoring requires additional tools\n",
    "    print(\"\\nNote: For detailed Metal GPU monitoring, use Activity Monitor or Instruments app\")\n",
    "\n",
    "# Example usage:\n",
    "# Run this when needed to check performance\n",
    "# monitor_performance(30)  # Monitor for 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define file paths\n",
    "    data_path = 'cleaned_training_data.csv.gz'  # Update with your actual path\n",
    "    model_save_path = 'chess_cnn_model.h5'\n",
    "    stockfish_path = \"/Users/kaust/stockfish/stockfish-windows-x86-64-avx2.exe\"  # Update with your path\n",
    "    \n",
    "    # Start overall timer\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Check if the training data exists\n",
    "    if not os.path.exists(data_path):\n",
    "        print(f\"Error: Training data file not found at {data_path}\")\n",
    "        return\n",
    "    \n",
    "    # Choose whether to train or test\n",
    "    mode = input(\"Enter 'train' to train a new model or 'test' to test an existing one: \").strip().lower()\n",
    "    \n",
    "    if mode == 'train':\n",
    "        # Train the model\n",
    "        print(\"\\n=== CNN TRAINING ===\")\n",
    "        print(\"Starting CNN training...\")\n",
    "        \n",
    "        training_start_time = time.time()\n",
    "        model = train_chess_cnn(data_path, model_save_path)\n",
    "        training_time = time.time() - training_start_time\n",
    "        \n",
    "        hours, remainder = divmod(training_time, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        print(f\"\\nTraining completed in {int(hours)}h {int(minutes)}m {seconds:.2f}s\")\n",
    "        \n",
    "    elif mode == 'test':\n",
    "        # Check if model exists\n",
    "        if not os.path.exists(model_save_path):\n",
    "            print(f\"Error: Model file not found at {model_save_path}\")\n",
    "            return\n",
    "        \n",
    "        # Test the model\n",
    "        print(\"\\n=== CNN TESTING ===\")\n",
    "        print(\"Testing the CNN model...\")\n",
    "        testing_start_time = time.time()\n",
    "        test_cnn_model(model_save_path, stockfish_path)\n",
    "        testing_time = time.time() - testing_start_time\n",
    "        \n",
    "        minutes, seconds = divmod(testing_time, 60)\n",
    "        print(f\"\\nTesting completed in {int(minutes)}m {seconds:.2f}s\")\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid mode. Please enter 'train' or 'test'.\")\n",
    "    \n",
    "    # Calculate total execution time\n",
    "    total_time = time.time() - start_time\n",
    "    hours, remainder = divmod(total_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    \n",
    "    print(f\"\\n=== EXECUTION COMPLETE ===\")\n",
    "    print(f\"Total execution time: {int(hours)}h {int(minutes)}m {seconds:.2f}s\")\n",
    "\n",
    "# Run the main function if executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try below code see which one you don't have a WARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model loaded successfully (without compilation).\n",
      "CNN model recompiled successfully with legacy Adam optimizer.\n"
     ]
    }
   ],
   "source": [
    "model_path = 'chess_cnn_model.h5'\n",
    "try:\n",
    "    cnn_model = tf.keras.models.load_model(model_path, compile=False)\n",
    "    print(\"CNN model loaded successfully (without compilation).\")\n",
    "    \n",
    "    # Use legacy Adam optimizer for M1/M2 Macs as recommended or AdamW\n",
    "    from tensorflow.keras.optimizers.legacy import Adam\n",
    "    cnn_model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),  \n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "    print(\"CNN model recompiled successfully with legacy Adam optimizer.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or compiling CNN model: {e}\")\n",
    "    cnn_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model loaded successfully (without compilation).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cnn_model = tf.keras.models.load_model(model_path, compile=False)\n",
    "    print(\"CNN model loaded successfully (without compilation).\")\n",
    "    \n",
    "    # Recompile with a supported optimizer\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    cnn_model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),  \n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or compiling CNN model: {e}\")\n",
    "    print(\"Will use SimpleChessEvaluator as fallback.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.AdamW` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.AdamW`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model loaded successfully (without compilation).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    cnn_model = tf.keras.models.load_model(model_path, compile=False)\n",
    "    print(\"CNN model loaded successfully (without compilation).\")\n",
    "    \n",
    "    # Recompile with AdamW optimizer\n",
    "    from tensorflow.keras.optimizers import AdamW\n",
    "    cnn_model.compile(\n",
    "        optimizer=AdamW(learning_rate=0.001),  \n",
    "        loss=\"mse\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or compiling CNN model: {e}\")\n",
    "    print(\"Will use SimpleChessEvaluator as fallback.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 14, 8, 64)         4672      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 14, 8, 64)         256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 8, 64)         36928     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 14, 8, 64)         256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 14, 8, 128)        73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 14, 8, 128)        147584    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 14, 8, 128)        512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 14, 8, 256)        295168    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 14, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 28672)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               14680576  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15372929 (58.64 MB)\n",
      "Trainable params: 15371649 (58.64 MB)\n",
      "Non-trainable params: 1280 (5.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output layer: dense_2, activation: tanh\n"
     ]
    }
   ],
   "source": [
    "output_layer = cnn_model.layers[-1]\n",
    "print(f\"Output layer: {output_layer.name}, activation: {output_layer.activation.__name__ if hasattr(output_layer.activation, '__name__') else output_layer.activation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSE150p_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
